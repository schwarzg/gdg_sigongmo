{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import itertools\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\YMS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size=8000\n",
    "unknown_token = \"UNKNOWN_TOKEN\"\n",
    "sentence_start_token = \"SENTENCE_START\"\n",
    "sentence_end_token = \"SENTENCE_END\"\n",
    "\n",
    "df = pd.read_csv(\"wine_data.csv\")\n",
    "df = df[\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_string=df.str.cat()\n",
    "\n",
    "train_string=train_string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 1000 sentences.\n"
     ]
    }
   ],
   "source": [
    "# Split full comment into sentences\n",
    "sentences=nltk.sent_tokenize(train_string)[:1000]\n",
    "\n",
    "# Append SENTENCE_START and SENTENCE_END\n",
    "sentences = [\"%s %s %s\" % (sentence_start_token, x, sentence_end_token) for x in sentences]\n",
    "\n",
    "print (\"Parsed %d sentences.\" % (len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3563 unique words tokens.\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the sentences into words\n",
    "tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "\n",
    "# Count the word frequencies\n",
    "word_freq = nltk.FreqDist(itertools.chain(*tokenized_sentences))\n",
    "print (\"Found %d unique words tokens.\" % len(word_freq.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using vocabulary size 8000.\n",
      "The least frequent word in our vocabulary is 'acidity.crisp' and appeared 1 times.\n"
     ]
    }
   ],
   "source": [
    "# Get the most common words and build index_to_word and word_to_index vectors\n",
    "vocab = word_freq.most_common(vocabulary_size-1)\n",
    "index_to_word = [x[0] for x in vocab]\n",
    "index_to_word.append(unknown_token)\n",
    "word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])\n",
    "\n",
    "print (\"Using vocabulary size %d.\" % vocabulary_size)\n",
    "print (\"The least frequent word in our vocabulary is '%s' and appeared %d times.\" % (vocab[-1][0], vocab[-1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example sentence: 'SENTENCE_START this tremendous 100% varietal wine hails from oakville and was aged over three years in oak. SENTENCE_END'\n",
      "\n",
      "Example sentence after Pre-processing: '['SENTENCE_START', 'this', 'tremendous', '100', '%', 'varietal', 'wine', 'hails', 'from', 'oakville', 'and', 'was', 'aged', 'over', 'three', 'years', 'in', 'oak', '.', 'SENTENCE_END']'\n",
      "[2, 9, 552, 292, 30, 349, 12, 1543, 19, 1544, 1, 319, 256, 224, 662, 168, 13, 40, 4, 3, 2, 53, 553, 20, 1, 7, 554, 92, 6, 387, 1545, 5, 17, 0, 320, 32, 121, 0, 225, 25, 1, 7, 321, 350, 1073, 13, 5, 555, 4, 3, 2, 90, 1, 1074, 19, 427, 15, 37, 0, 11, 34, 168, 1546, 6, 11, 15, 351, 481, 1547, 4, 3, 2, 226, 1548, 22, 6, 663, 0, 49, 1, 139, 28, 826, 1, 1549, 32, 7, 1550, 6, 272, 72, 1, 58, 4, 3, 2, 9, 10, 63, 0, 273, 0, 201, 1, 1551, 16, 5, 17, 0, 8, 46, 14, 6, 428, 23, 43, 1, 179, 257, 4, 3, 2, 7, 180, 0, 1552, 37, 10, 429, 31, 1553, 90, 4, 3, 2, 21, 33, 1554, 1555, 1556, 5, 1557, 6, 7, 12, 322, 144, 32, 1075, 1558, 13, 9, 1076, 169, 0, 90, 1, 100, 1559, 50, 4, 3, 2, 59, 1560, 13, 116, 0, 11, 212, 235, 556, 0, 91, 1077, 1, 87, 213, 14, 0, 1561, 13, 5, 1562, 6, 44, 1563, 1564, 6, 664, 1565, 1078, 388, 323, 13, 236, 30, 140, 324, 40, 0, 1, 1566, 20, 19, 1079, 18, 1567, 0, 1568, 1, 1569, 293, 0, 482, 1080, 4, 3, 2, 145, 0, 122, 1, 180, 0, 11, 1081, 352, 22, 1, 14, 6, 117, 0, 1082, 1083, 0, 49, 0, 23, 26, 0, 146, 1, 430, 4, 3, 2, 25, 28, 294, 15, 7, 225, 1570, 0, 1, 1571, 7, 37, 827, 8, 59, 72, 1, 237, 4, 3, 2, 21, 77, 33, 1572, 10, 5, 1084, 12, 19, 1085, 1573, 0, 557, 238, 5, 1574, 558, 13, 5, 81, 78, 1575, 559, 4, 3, 2, 11, 34, 108, 0, 483, 1, 665, 27, 24, 10, 73, 1576, 295, 4, 3, 2, 8, 828, 323, 13, 104, 0, 5, 12, 34, 560, 47, 829, 258, 1, 214, 4, 3, 2, 296, 32, 5, 1577, 389, 0, 1086, 6, 830, 1578, 13, 1579, 0, 11, 10, 7, 12, 144, 35, 118, 4, 3, 2, 21, 19, 1580, 0, 122, 1, 353, 19, 5, 561, 1087, 0, 9, 562, 10, 7, 1581, 4, 3, 2, 22, 6, 59, 29, 23, 43, 28, 431, 1, 666, 563, 4, 3, 2, 9, 484, 831, 16, 5, 17, 31, 1582, 90, 4, 3, 2, 14, 6, 49, 0, 146, 0, 123, 1, 180, 40, 37, 155, 0, 124, 1, 429, 4, 3, 2, 21, 9, 1583, 562, 33, 1584, 1088, 564, 22, 485, 7, 111, 93, 6, 832, 105, 8, 7, 92, 6, 354, 4, 3, 2, 1585, 1586, 1587, 24, 125, 1588, 6, 181, 18, 182, 28, 1589, 4, 3, 2, 14, 6, 49, 0, 123, 1, 72, 28, 1590, 274, 1, 1089, 0, 60, 9, 1591, 355, 16, 7, 156, 37, 4, 3, 2, 21, 77, 33, 1592, 1090, 564, 22, 28, 1593, 1, 565, 57, 6, 833, 1, 58, 4, 3, 2, 9, 1594, 10, 831, 1, 141, 16, 5, 17, 0, 31, 73, 325, 1, 667, 4, 3, 2, 72, 10, 7, 1595, 137, 0, 60, 202, 45, 1, 139, 14, 28, 1596, 1597, 4, 3, 2, 16, 5, 37, 0, 9, 10, 141, 1, 326, 41, 7, 668, 1598, 4, 3, 2, 21, 9, 1599, 1600, 562, 33, 1091, 1601, 81, 319, 1086, 1092, 41, 1602, 4, 3, 2, 215, 239, 356, 1603, 147, 1604, 669, 23, 43, 4, 3, 2, 432, 6, 74, 1, 430, 1605, 0, 8, 1093, 486, 214, 4, 3, 2, 9, 10, 7, 12, 15, 357, 0, 487, 11, 10, 240, 227, 834, 4, 3, 2, 21, 77, 33, 1094, 390, 1095, 19, 391, 1606, 6, 5, 81, 35, 9, 1607, 78, 7, 488, 835, 0, 112, 1096, 70, 27, 4, 3, 2, 1608, 216, 0, 566, 1, 87, 213, 14, 1097, 327, 0, 670, 212, 6, 54, 24, 567, 41, 297, 20, 4, 3, 2, 24, 836, 325, 137, 34, 665, 1609, 0, 392, 1, 108, 157, 183, 13, 9, 1610, 837, 1611, 1612, 482, 1098, 18, 1613, 1099, 4, 3, 2, 11, 131, 8, 1100, 193, 568, 358, 0, 145, 138, 1, 489, 20, 119, 4, 3, 2, 5, 158, 0, 169, 17, 1614, 569, 53, 50, 84, 0, 29, 91, 1, 74, 14, 60, 50, 433, 1, 120, 88, 57, 1101, 5, 298, 1102, 1615, 241, 0, 9, 328, 434, 671, 352, 14, 6, 123, 0, 26, 0, 58, 1, 1103, 359, 4, 3, 2, 1616, 490, 1, 169, 570, 78, 9, 571, 435, 0, 9, 12, 393, 1617, 35, 7, 156, 1, 120, 357, 1618, 4, 3, 2, 21, 77, 33, 1619, 838, 570, 13, 9, 1620, 1104, 6, 572, 1621, 19, 1622, 94, 0, 5, 1623, 131, 8, 7, 1105, 6, 299, 1, 95, 119, 1, 432, 4, 3, 2, 11, 573, 0, 321, 1, 672, 0, 8, 14, 6, 1624, 0, 58, 0, 359, 1, 436, 72, 1625, 1626, 33, 29, 49, 1627, 12, 10, 13, 1106, 1628, 4, 3, 2, 5, 25, 1, 5, 673, 14, 839, 9, 29, 1629, 12, 4, 3, 2, 5, 20, 10, 125, 132, 41, 67, 491, 65, 360, 1, 228, 6, 1107, 492, 4, 3, 2, 11, 10, 7, 1630, 12, 437, 78, 5, 558, 6, 493, 8, 159, 5, 174, 14, 1, 5, 20, 13, 5, 437, 1631, 44, 840, 242, 6, 88, 0, 674, 1, 126, 43, 0, 9, 494, 671, 1632, 19, 427, 15, 37, 4, 3, 2, 328, 1, 122, 0, 11, 18, 841, 184, 0, 243, 0, 39, 1, 23, 26, 0, 7, 109, 6, 72, 0, 1, 24, 574, 575, 6, 88, 4, 3, 2, 125, 361, 675, 28, 13, 133, 1633, 1, 37, 8, 47, 576, 327, 54, 4, 3, 2, 11, 18, 169, 240, 0, 31, 160, 11, 676, 1108, 35, 63, 842, 4, 3, 2, 21, 77, 33, 1634, 144, 13, 1635, 0, 9, 670, 1109, 185, 10, 125, 677, 147, 4, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Replace all words not in our vocabulary with the unknown token\n",
    "for i, sent in enumerate(tokenized_sentences):\n",
    "    tokenized_sentences[i] = [w if w in word_to_index else unknown_token for w in sent]\n",
    "\n",
    "print (\"\\nExample sentence: '%s'\" % sentences[0])\n",
    "print (\"\\nExample sentence after Pre-processing: '%s'\" % tokenized_sentences[0])\n",
    "\n",
    "#One-hot vectorized\n",
    "#ind_sent=np.append([[word_to_index[w] for w in sent] for sent in tokenized_sentences],[])\n",
    "X_tr=[]\n",
    "for sent in tokenized_sentences:\n",
    "\tX_tr=X_tr+[word_to_index[w] for w in sent] \n",
    "print (X_tr[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxx = 0\n",
    "for i in range(len(tokenized_sentences)):\n",
    "    if len(tokenized_sentences[i]) >= maxx:\n",
    "        maxx = len(tokenized_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28728"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3564"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28728, 3564)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot =  np.zeros([len(X_tr),len(word_to_index)])\n",
    "one_hot.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_tr)):\n",
    "    one_hot[i,X_tr[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28728, 3564)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_data = np.zeros([27709, 20, 3564])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27709, 20, 3564)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = 20\n",
    "empty_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(empty_data.shape[0]):\n",
    "    spot = -1\n",
    "    for j in range(i, i+L):\n",
    "        spot += 1\n",
    "        empty_data[i,spot,:] = one_hot[j,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dat = empty_data[:,:L-1,:]\n",
    "y_dat = empty_data[:,L-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27709, 3564)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-2b09ced53d7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_dat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_dat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2211\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n\u001b[1;32m-> 2212\u001b[1;33m                                      safe_indexing(a, test)) for a in arrays))\n\u001b[0m\u001b[0;32m   2213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2211\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n\u001b[1;32m-> 2212\u001b[1;33m                                      safe_indexing(a, test)) for a in arrays))\n\u001b[0m\u001b[0;32m   2213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36msafe_indexing\u001b[1;34m(X, indices)\u001b[0m\n\u001b[0;32m    214\u001b[0m                                    indices.dtype.kind == 'i'):\n\u001b[0;32m    215\u001b[0m             \u001b[1;31m# This is often substantially faster than X[indices]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_size = 0.7\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_dat, y_dat, train_size = train_size, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.recurrent import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-73-96c16a936c70>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-73-96c16a936c70>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    epochs =\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "maxlen = 20\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(n_hidden,\n",
    "                   init = weight_variable,\n",
    "                   input_shape = (maxlen, n_out)))\n",
    "model.add(Dense(n_out, init = weight_variable))\n",
    "modell.add(Activation('linear'))\n",
    "optimizer = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)\n",
    "model-compile(loss = 'mean_squared_error',\n",
    "             optimizer = optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 10 \n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "         batch_size = batch_size,\n",
    "         epechs = epochs,\n",
    "         validation_data = (X_validation, Y_vlaidation),\n",
    "         callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncate = maxlen\n",
    "Z= x_dat[:1,:,:]\n",
    "original = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=115)\n",
    "x_val = sequence.pad_sequences(x_val, maxlen=115)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SENTENCE_START',\n",
       " 'juicy',\n",
       " 'red-cherry',\n",
       " 'fruit',\n",
       " 'and',\n",
       " 'a',\n",
       " 'compelling',\n",
       " 'hint',\n",
       " 'of',\n",
       " 'caramel',\n",
       " 'greet',\n",
       " 'the',\n",
       " 'palate',\n",
       " ',',\n",
       " 'framed',\n",
       " 'by',\n",
       " 'elegant',\n",
       " ',',\n",
       " 'fine',\n",
       " 'tannins',\n",
       " 'and',\n",
       " 'a',\n",
       " 'subtle',\n",
       " 'minty',\n",
       " 'tone',\n",
       " 'in',\n",
       " 'the',\n",
       " 'background',\n",
       " '.',\n",
       " 'SENTENCE_END']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 3., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3564\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5, 3564) (2, 1, 3564)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
